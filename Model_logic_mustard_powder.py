import torch
import torch.nn as nn
from torchvision import transforms
from torchvision.models import mobilenet_v2, MobileNet_V2_Weights
import contextlib

# ====== Configuration ======
IMAGE_SIZE = (512, 512)
NUM_CLASSES = 5
MODEL_PATH = 'best_mobilenetv2_finegrained_model.pth'
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
USE_AMP = torch.cuda.is_available()
amp_autocast = torch.cuda.amp.autocast if USE_AMP else contextlib.nullcontext

# ====== CBAM Module ======
class CBAM(nn.Module):
    def __init__(self, channels, reduction=16, kernel_size=7):
        super().__init__()
        self.channel_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels, channels // reduction, 1, bias=False),
            nn.ReLU(),
            nn.Conv2d(channels // reduction, channels, 1, bias=False),
            nn.Sigmoid()
        )
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        ca = self.channel_attention(x) * x
        sa = self.spatial_attention(torch.cat(
            [ca.mean(1, keepdim=True), ca.max(1, keepdim=True)[0]], dim=1))
        return sa * ca

# ====== Model Definition ======
class FineGrainedNet(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        weights = MobileNet_V2_Weights.DEFAULT
        backbone = mobilenet_v2(weights=weights)
        self.feature_extractor = backbone.features 

        self.cbam = CBAM(1280)  

        self.head = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(1280, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        x = self.feature_extractor(x)
        x = self.cbam(x)
        x = self.head(x)
        return x

# ====== Load Model ======
@torch.no_grad()
def load_model():
    model = FineGrainedNet(NUM_CLASSES).to(DEVICE)
    state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
    model.load_state_dict(state_dict)
    model.eval()
    return model

# ====== Image Preprocessing ======
def preprocess_image(image):
    transform = transforms.Compose([
        transforms.Resize(IMAGE_SIZE),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ])
    return transform(image).unsqueeze(0).to(DEVICE)

# ====== Labels ======
class_names = [
    "Powdery Mildew infection affecting mustard plants: SCORE 1 to 3",
    "Powdery Mildew infection affecting mustard plants: SCORE 5",
    "Powdery Mildew infection affecting mustard plants: SCORE 7",
    "Powdery Mildew infection affecting mustard plants: SCORE 9",
    "Healthy Mustard Plant"
]

original_labels = [
    'SCORE_1_3',
    'SCORE_5',
    'SCORE_7',
    'SCORE_9',
    'mustard_healthy'
]

remedies = {
    'SCORE_1_3': "üü° **Mild Powdery Mildew Infection**: Few spots observed. Monitor crop regularly and ensure proper air circulation.",
    'SCORE_5': "üü† **Moderate Infection**: Apply sulfur-based fungicides or organic treatments like baking soda spray. Remove affected leaves if possible.",
    'SCORE_7': "üî¥ **Severe Infection**: Large patches observed. Use recommended fungicides and avoid overhead watering. Improve plant spacing.",
    'SCORE_9': "üî¥‚ùó **Very Severe Infection**: Extensive mildew present. Immediate chemical fungicide intervention is required. Consider crop rotation in future.",
    'mustard_healthy': "‚úÖ Your mustard plant appears healthy. Maintain proper spacing and monitor for early signs of powdery mildew."
}
